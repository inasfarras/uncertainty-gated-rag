# ==== MODEL & PROVIDER ====
# Pilih salah satu: openai | ollama | local
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini                # untuk openai; ganti sesuai kebutuhan
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# ==== OPENAI (jika LLM_PROVIDER=openai) ====
OPENAI_API_KEY=sk-your-key-here
# (opsional) custom endpoint, misal Azure/OpenAI-compatible proxy
OPENAI_BASE_URL=

# ==== OLLAMA (jika LLM_PROVIDER=ollama) ====
OLLAMA_HOST=http://localhost:11434
# contoh model: llama3.1:8b, qwen2.5:7b-instruct
OLLAMA_MODEL=llama3.1:8b

# ==== RAG DEFAULTS (bisa di-tune saat eksperimen) ====
MAX_TOKENS_TOTAL=3500       # total token budget per query (retrieval+generate)
MAX_ROUNDS=2                # jumlah iterasi maksimum (gate loop)
RETRIEVAL_K=8               # top-k untuk vector retriever
GRAPH_K=20                  # top-k untuk graph/KG retriever (jika dipakai)
FAITHFULNESS_TAU=0.75       # ambang "cukup setia" ke konteks
OVERLAP_TAU=0.50            # ambang dukungan/overlap
LOW_BUDGET_TOKENS=500       # jika sisa token < ini â†’ STOP_LOW_CONF
USE_RERANK=true             # true/false (string) untuk aktifkan bge-reranker

# ==== PATHS / ARTIFACTS ====
DATA_DIR=./data/corpus              # folder sumber data mentah (.txt/.jsonl)
INDEX_DIR=./artifacts/faiss         # lokasi index FAISS + metadata
LOG_DIR=./artifacts/logs            # simpan JSONL log langkah/aksi
REPORT_DIR=./artifacts/reports      # output ringkasan/CSV

# ==== API (opsional untuk FastAPI) ====
API_HOST=0.0.0.0
API_PORT=8000

# ==== MISC ====
LOG_LEVEL=INFO          # DEBUG | INFO | WARNING | ERROR
SEED=42
